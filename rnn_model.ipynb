{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For uploading data\n",
    "# from google.colab import files\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "# Model\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Testing\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Finding function to relate epochs & loss\n",
    "# from scipy.optimize import curve_fit\n",
    "\n",
    "# Allows for panning or zooming in plots\n",
    "# %matplotlib inline\n",
    "\n",
    "# Yahoo finance for data\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Loading & Visualizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Open      High       Low     Close      Volume  \\\n",
      "Date                                                                            \n",
      "1986-03-13 00:00:00-05:00  0.054693  0.062736  0.054693  0.060055  1031788800   \n",
      "1986-03-14 00:00:00-05:00  0.060055  0.063272  0.060055  0.062199   308160000   \n",
      "1986-03-17 00:00:00-05:00  0.062199  0.063808  0.062199  0.063272   133171200   \n",
      "1986-03-18 00:00:00-05:00  0.063272  0.063808  0.061127  0.061663    67766400   \n",
      "1986-03-19 00:00:00-05:00  0.061663  0.062199  0.060055  0.060591    47894400   \n",
      "\n",
      "                           Dividends  Stock Splits  \n",
      "Date                                                \n",
      "1986-03-13 00:00:00-05:00        0.0           0.0  \n",
      "1986-03-14 00:00:00-05:00        0.0           0.0  \n",
      "1986-03-17 00:00:00-05:00        0.0           0.0  \n",
      "1986-03-18 00:00:00-05:00        0.0           0.0  \n",
      "1986-03-19 00:00:00-05:00        0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "# Load data with yahoo finance library\n",
    "aapl = yf.Ticker(\"AAPL\")\n",
    "tsla = yf.Ticker(\"TSLA\")\n",
    "amzn = yf.Ticker(\"AMZN\")\n",
    "msft = yf.Ticker(\"MSFT\")\n",
    "googl = yf.Ticker(\"GOOGL\")\n",
    "tickers = [aapl, tsla, amzn, msft, googl] # Randomly chosen by chatGPT\n",
    "\n",
    "# Historical data usage (for reference):\n",
    "hist = msft.history(period=\"max\")\n",
    "# print(\"type(hist):\", type(hist))  # It's a dataframe baby\n",
    "print(hist.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Train test split + Model Construction and Training all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[yfinance.Ticker object <AAPL>, yfinance.Ticker object <TSLA>, yfinance.Ticker object <AMZN>, yfinance.Ticker object <MSFT>, yfinance.Ticker object <GOOGL>]\n",
      "yfinance.Ticker object <AAPL>\n",
      "yfinance.Ticker object <TSLA>\n",
      "yfinance.Ticker object <AMZN>\n",
      "yfinance.Ticker object <MSFT>\n",
      "yfinance.Ticker object <GOOGL>\n"
     ]
    }
   ],
   "source": [
    "print(tickers)\n",
    "for ticker in tickers: print(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for yfinance.Ticker object <AAPL>\n",
      "Epoch 1/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 463us/step - loss: 2.1893\n",
      "Epoch 2/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 116.6340\n",
      "Epoch 3/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 51.4044\n",
      "Epoch 4/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 32.3913\n",
      "Epoch 5/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 18.1979\n",
      "Epoch 6/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 8.4047\n",
      "Epoch 7/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 4.2050\n",
      "Epoch 8/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 3.2470\n",
      "Epoch 9/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 2.5273\n",
      "Epoch 10/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 2.4229\n",
      "Epoch 11/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 2.2541\n",
      "Epoch 12/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 2.0423\n",
      "Epoch 13/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 1.9395\n",
      "Epoch 14/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 1.9289\n",
      "Epoch 15/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 1.6446\n",
      "Epoch 16/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 1.6090\n",
      "Epoch 17/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 1.6897\n",
      "Epoch 18/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 1.7013\n",
      "Epoch 19/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 1.6056\n",
      "Epoch 20/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 1.5470\n",
      "Epoch 21/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 1.4161\n",
      "Epoch 22/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 1.4660\n",
      "Epoch 23/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 1.6157\n",
      "Epoch 24/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 1.4192\n",
      "Epoch 25/25\n",
      "\u001b[1m963/963\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 1.5275\n",
      "Training model for yfinance.Ticker object <TSLA>\n",
      "Epoch 1/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 140.0884\n",
      "Epoch 2/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 262.4135\n",
      "Epoch 3/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 125.9295\n",
      "Epoch 4/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 121.3552\n",
      "Epoch 5/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 123.6257\n",
      "Epoch 6/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 137.7961\n",
      "Epoch 7/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 127.2392\n",
      "Epoch 8/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 131.4544\n",
      "Epoch 9/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 122.3216\n",
      "Epoch 10/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 143.0544\n",
      "Epoch 11/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 140.5540\n",
      "Epoch 12/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 123.7165\n",
      "Epoch 13/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 121.7876\n",
      "Epoch 14/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 150.6208\n",
      "Epoch 15/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 127.2892\n",
      "Epoch 16/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 119.2288\n",
      "Epoch 17/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 134.7365\n",
      "Epoch 18/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 155.9418\n",
      "Epoch 19/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 119.5326\n",
      "Epoch 20/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 139.8876\n",
      "Epoch 21/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 127.4368\n",
      "Epoch 22/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 116.2315\n",
      "Epoch 23/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 122.4922\n",
      "Epoch 24/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 120.9422\n",
      "Epoch 25/25\n",
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 118.6421\n",
      "Training model for yfinance.Ticker object <AMZN>\n",
      "Epoch 1/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 39.4136\n",
      "Epoch 2/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 146.7584\n",
      "Epoch 3/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 42.8334\n",
      "Epoch 4/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 27.9374\n",
      "Epoch 5/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 24.6304\n",
      "Epoch 6/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 22.5149\n",
      "Epoch 7/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 20.1332\n",
      "Epoch 8/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 17.6966\n",
      "Epoch 9/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 17.1993\n",
      "Epoch 10/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 14.7682\n",
      "Epoch 11/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 15.7659\n",
      "Epoch 12/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 14.7928\n",
      "Epoch 13/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 16.4257\n",
      "Epoch 14/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 15.3647\n",
      "Epoch 15/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 17.1670\n",
      "Epoch 16/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 16.5884\n",
      "Epoch 17/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 15.5746\n",
      "Epoch 18/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 15.2376\n",
      "Epoch 19/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 16.1013\n",
      "Epoch 20/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 16.2931\n",
      "Epoch 21/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 14.9708\n",
      "Epoch 22/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 15.2117\n",
      "Epoch 23/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 15.9204\n",
      "Epoch 24/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 14.8855\n",
      "Epoch 25/25\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 15.5708\n",
      "Training model for yfinance.Ticker object <MSFT>\n",
      "Epoch 1/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 22.8256\n",
      "Epoch 2/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 235.1778\n",
      "Epoch 3/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 61.2629\n",
      "Epoch 4/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 34.0181\n",
      "Epoch 5/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 29.3437\n",
      "Epoch 6/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 25.3281\n",
      "Epoch 7/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 23.7294\n",
      "Epoch 8/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 23.5348\n",
      "Epoch 9/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 20.8926\n",
      "Epoch 10/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 19.9453\n",
      "Epoch 11/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 20.2042\n",
      "Epoch 12/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 19.1061\n",
      "Epoch 13/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 19.6221\n",
      "Epoch 14/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 20.7468\n",
      "Epoch 15/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 17.9536\n",
      "Epoch 16/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 20.7704\n",
      "Epoch 17/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 18.7946\n",
      "Epoch 18/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 18.5540\n",
      "Epoch 19/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 18.7389\n",
      "Epoch 20/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 18.9210\n",
      "Epoch 21/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 19.3524\n",
      "Epoch 22/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 18.8084\n",
      "Epoch 23/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 17.9964\n",
      "Epoch 24/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 18.3320\n",
      "Epoch 25/25\n",
      "\u001b[1m847/847\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 18.2359\n",
      "Training model for yfinance.Ticker object <GOOGL>\n",
      "Epoch 1/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 69.5387\n",
      "Epoch 2/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 126.8882\n",
      "Epoch 3/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 78.9843\n",
      "Epoch 4/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 61.8312\n",
      "Epoch 5/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 53.3909\n",
      "Epoch 6/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - loss: 42.3606\n",
      "Epoch 7/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 44.7621\n",
      "Epoch 8/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 41.5570\n",
      "Epoch 9/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 40.2816\n",
      "Epoch 10/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 39.3044\n",
      "Epoch 11/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 39.7657\n",
      "Epoch 12/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 43.9510\n",
      "Epoch 13/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 39.9139\n",
      "Epoch 14/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 37.9886\n",
      "Epoch 15/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 42.0900\n",
      "Epoch 16/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 43.1806\n",
      "Epoch 17/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 39.6575\n",
      "Epoch 18/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 41.2204\n",
      "Epoch 19/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 38.1215\n",
      "Epoch 20/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 38.0648\n",
      "Epoch 21/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 40.9126\n",
      "Epoch 22/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 40.8184\n",
      "Epoch 23/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 36.1633\n",
      "Epoch 24/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 42.4339\n",
      "Epoch 25/25\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 41.0822\n"
     ]
    }
   ],
   "source": [
    "# This stuff is global & consistent across all tickers\n",
    "# Pre-processing\n",
    "Scaler = MinMaxScaler()\n",
    "# Splitting Data\n",
    "num_splits = 7 # Modifiable\n",
    "num_epochs=25\n",
    "tss = TimeSeriesSplit(n_splits=num_splits)\n",
    "# Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Loss Summary\n",
    "lossDict = {} # Ticker: array of losses, will average out later\n",
    "## This is the general structure I think:\n",
    "for ticker in tickers:\n",
    "    # Separate inputs & outputs\n",
    "    hist = ticker.history(period=\"max\")\n",
    "    inputs = hist[['Open', 'High', 'Low', 'Volume']]\n",
    "    outputs = hist['Close']\n",
    "\n",
    "    # Preprocess w/MinMaxScaler to make operations less intensive\n",
    "    df = Scaler.fit_transform(inputs)\n",
    "    df = pd.DataFrame(columns=inputs.columns, data=df, index=hist.index)\n",
    "\n",
    "\n",
    "    # Split data into training & testing\n",
    "\n",
    "    X_train, X_test, y_train, y_test = None, None, None, None # Init now to avoid scope issues\n",
    "    # i love github copilot sm\n",
    "    for train_index, test_index in tss.split(df):\n",
    "        # X_train = everything in df until train_index\n",
    "        # X_test = everything in df after train_index\n",
    "        X_train, X_test = df[:len(train_index)], df[len(train_index):]\n",
    "        y_train, y_test = outputs[:len(train_index)], outputs[len(train_index):]\n",
    "\n",
    "    # Reshape data for LSTM\n",
    "    X_train = np.array(X_train).reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "    X_test = np.array(X_test).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "    # Train\n",
    "    lossDict[ticker] = []\n",
    "    print(\"Training model for\", ticker)\n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=10, verbose=1, shuffle=False)\n",
    "    lossDict[ticker].append(history.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yfinance.Ticker object <AAPL> : 22.929141731262206\n",
      "yfinance.Ticker object <TSLA> : 1306.60736328125\n",
      "yfinance.Ticker object <AMZN> : 225.48595703125\n",
      "yfinance.Ticker object <MSFT> : 123.69180084228516\n",
      "yfinance.Ticker object <GOOGL> : 236.04610717773437\n"
     ]
    }
   ],
   "source": [
    "# print(lossDict)\n",
    "\n",
    "for key in lossDict.keys():\n",
    "    lossDict[key] = np.mean(lossDict[key])\n",
    "    print(key, \":\", lossDict[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
